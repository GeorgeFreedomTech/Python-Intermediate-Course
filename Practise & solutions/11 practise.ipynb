{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05609806",
   "metadata": {},
   "source": [
    "## practice\n",
    "\n",
    "**Scenario:** You are a data operative tasked with extracting specific intel from publicly available web sources (static web pages).\n",
    "\n",
    "**1. Basic Reconnaissance:**\n",
    "- Go to a simple, static web page. \n",
    "- Inspect its structure in your browser using DevTools (`F12`) to identify the HTML tags that contain the data you want.\n",
    "- Using `requests` and `BeautifulSoup` in a Python script:\n",
    "    - **a)** Extract all visible text from the main body of the page and print it to the console.\n",
    "    - **b)** Extract all links, headlines or anything else from the page and print them as a list.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Challenge I: Modular Scraping Tool**\n",
    "- Refactor your code from the previous exercise into one or more functions.\n",
    "- Create a main function that accepts a `url` as a parameter to make your scraper reusable for different targets.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Challenge II: Data Archiving**\n",
    "- Modify your function(s) to save the extracted results to a local file.\n",
    "- If the file doesn't exist, it should be created. If it does exist, the new data should be appended.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Challenge III: Timestamped Logging**\n",
    "- Enhance your function(s) from the previous challenge.\n",
    "- Each time you run a scrape on a URL, the new results should be appended to the existing log file.\n",
    "- Before writing the new results for a scrape session, your script should first write a header line with the **current date and time** to timestamp when that specific data was gathered. This allows your log file to store a history of multiple reconnaissance runs over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e162f68",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "- Only look at the solutions after you have tried solving the exercises `using your own effort` and are truly stuck.\n",
    "- `There are usually multiple ways to solve a task.`\n",
    "- The solutions below use `knowledge that the student has right now` (= from lessons covered so far) and focus on practicing the `topics currently being discussed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d28958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "# 1.\n",
    "url = \"https://www.example.com\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# a)\n",
    "print(response.text) \n",
    "\n",
    "# b)\n",
    "if response.status_code == 200: # check if the request was successful\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        links.append(link.get(\"href\"))\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage.\", response.status_code)\n",
    "\n",
    "\n",
    "# challenge I.\n",
    "def get_page_content(url: str) -> str:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    return \"\" # Return empty string on failure\n",
    "\n",
    "def extract_links_from_html(html_text: str) -> list:\n",
    "    if not html_text:\n",
    "        return []\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    links_list = [link.get('href') for link in soup.find_all('a') if link.get('href')]\n",
    "    return links_list\n",
    "\n",
    "# Use:\n",
    "url = \"https://www.example.com\"\n",
    "print(get_page_content(url))\n",
    "print(extract_links_from_html(get_page_content(url)))\n",
    "\n",
    "\n",
    "# challenge II.\n",
    "def save_log_entry(data, file_path: str) -> None:\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(data, \"\\n\")\n",
    "            return\n",
    "    else:\n",
    "        with open(file_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(data + \"\\n\")\n",
    "            return\n",
    "\n",
    "# Use:\n",
    "url = \"https://www.example.com\"\n",
    "data = str(extract_links_from_html(get_page_content(url)))\n",
    "file_path = \"log.txt\"\n",
    "save_log_entry(data, file_path)\n",
    "\n",
    "# challenge III.\n",
    "def get_current_datetime() -> str:\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Use:\n",
    "url = \"https://www.example.com\"\n",
    "file_path = \"log.txt\"\n",
    "data = get_current_datetime() + \"\\n\" + str(extract_links_from_html(get_page_content(url)))\n",
    "save_log_entry(data, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161b9760",
   "metadata": {},
   "source": [
    "---\n",
    "#### © Jiří Svoboda (George Freedom)\n",
    "- Web: https://GeorgeFreedom.com\n",
    "- LinkedIn: https://www.linkedin.com/in/georgefreedom/\n",
    "- Book me: https://cal.com/georgefreedom"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
