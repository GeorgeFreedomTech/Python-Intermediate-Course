{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d477382b",
   "metadata": {},
   "source": [
    "## practice\n",
    "\n",
    "**Scenario:** You are a data operative tasked with gathering intelligence from various online sources (APIs and web pages).\n",
    "\n",
    "**1. Basic Reconnaissance:**\n",
    "- Choose a simple webpage or API endpoint. For example, use `http://api.open-notify.org/iss-now.json` for structured data, or `https://example.com` for simple HTML.\n",
    "- **Before coding**, it's good practice to inspect the URL in your browser, using DevTools (`F12`) to see what kind of data to expect.\n",
    "- Using the `requests` library in a Python script, get the response from your chosen URL.\n",
    "- Print the following information to your console:\n",
    "    - The final URL and the status code of the response.\n",
    "    - The response headers and any cookies.\n",
    "    - The content of the page (either HTML or JSON according on Content-Type - see Headers)..\n",
    "\n",
    "---\n",
    "\n",
    "**2. Challenge I: Archiving Retrieved Data**\n",
    "- Building on the previous exercise, save the content you retrieved (the HTML text or JSON data) to a local file named `recon_data.txt`.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Challenge II: Creating a Reusable Data Retrieval Tool**\n",
    "- Create two functions to make your data gathering process modular:\n",
    "    - **a) `get_content(url: str) -> str:`**\n",
    "        - This function should take a URL string as a parameter.\n",
    "        - If successful, it should `return` the content as a string.\n",
    "    - **b) `save_content(data: str, file_path: str) -> None:`**\n",
    "        - This function takes a string of data and a file path as parameters.\n",
    "        - It then writes the provided data into the specified file.\n",
    "- In the main part of your script, combine these two functions: call `fetch_content_from_url()` and `save_content_to_file()` to save it. Verify that the file was created and contains the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437891e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "target_url = \"http://example.com\" # Using a simple, stable URL for the example\n",
    "response = requests.get(url=target_url)\n",
    "\n",
    "print(response.url)\n",
    "print(response.status_code)\n",
    "print(response.cookies)\n",
    "print(response.headers)\n",
    "print(response.text)\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "# Challenge I:\n",
    "with open(\"recon_data.txt\", \"w\", encoding=\"utf-8\") as scraped_page:\n",
    "    scraped_page.write(response.text)\n",
    "\n",
    "# ---\n",
    "\n",
    "# Challenge II: \n",
    "def get_content(url):\n",
    "    response = requests.get(url=url)\n",
    "    return response.text\n",
    "\n",
    "def save_content(text, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "        output_file.write(text)\n",
    "\n",
    "# Use:\n",
    "save_content(get_content(target_url), \"recon_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33df390",
   "metadata": {},
   "source": [
    "---\n",
    "#### © Jiří Svoboda (George Freedom)\n",
    "- Web: https://GeorgeFreedom.com\n",
    "- LinkedIn: https://www.linkedin.com/in/georgefreedom/\n",
    "- Book me: https://cal.com/georgefreedom"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
